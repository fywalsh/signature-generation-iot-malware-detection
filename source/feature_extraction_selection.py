#!/usr/bin/env python

"""
Creates System Call N-grams based on the specified parameter.  Calculates the TF-IDF weight for each of the System Call
N-grams and discards all System Call N-grams outside the top N features (ordered by term frequency across the corpus
of .dat files).  Converts all non-zero TF-IDF weights to 1.  A non-zero TF-IDF weight means that the System Call N-gram
appears in particular trace log and as such can potentially be used for classification.  The results are formatted and
output as a CSV file.
"""

# Generic/Built-in
import argparse
import datetime
import glob
import os

# Libs
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer

__author__ = "Fiona Walsh"
__version__ = "1.0.0"
__status__ = "Dev"


def perform_fet_ext_sel(arguments, now):
    """
    Performs Feature Extraction and Selection

    Args:
        arguments: Input Directory, Size of N-grams, Top max features ordered by term frequency across the corpus,
                Output Directory
        now: Current date and time

    Returns:
        None
    """
    raw_docs_filepath = glob.glob(os.path.join(arguments.input, "*.dat"))
    
    # Creates an instance of TfidfVectorizer
    tfidf = TfidfVectorizer(input='filename', ngram_range=(arguments.ngram, arguments.ngram),
                            max_features=arguments.topn)
    
    # Convert the collection of .DAT files to a matrix of TF-IDF features
    response = tfidf.fit_transform(raw_docs_filepath)
    
    # Create a dataframe to store the formatted results
    syscall_df = pd.DataFrame()
    syscall_df['system_calls'] = tfidf.get_feature_names()

    label_df = pd.DataFrame()

    count = 0
    malware_count = 0
    benign_count = 0
    
    # Populate the dataframe with the TF-IDF weights
    with open(args.output + "feature_ext_sel_processed_files.log", 'w') as processed_files:
        for file in raw_docs_filepath:
            syscall_df[str(count + 1)] = response.toarray()[count]
            filetype = file[file.rfind("_") + 1:-4]

            if filetype == "benign":
                benign_count += 1
            else:
                malware_count += 1

            label_df[str(count + 1)] = [filetype]
            count += 1

            processed_files.write("Processed file: {}".format(file))

    print("Total Syscall Logs Processed: {} (Malware: {}, Benign: {})".format(count, malware_count, benign_count))

    syscall_df.set_index('system_calls', inplace=True)

    # Convert all TF-IDF scores greater than 0 to 1
    syscall_df[syscall_df > 0] = 1
    
    # Format final results before saving to CSV
    final_df = pd.concat([syscall_df.T, label_df.T], axis=1)
    final_df.columns = [*final_df.columns[:-1], 'label']
    filename = arguments.output + "syscall_top" + str(arguments.topn) + "_features_" + now + ".csv"
    final_df.to_csv(filename, index=False, sep=',', mode='a')

    print("\nCreated system call top features datatset file: {}".format(filename))


if __name__ == '__main__':
    print('Running Script: {}'.format(__file__))

    parser = argparse.ArgumentParser(prog=__file__,
                                     usage='%(prog)s [options]',
                                     description='Performs feature extraction and selection')

    parser = argparse.ArgumentParser()

    parser.add_argument("-i", "--input", help="Input directory")
    parser.add_argument("-o", "--output", help="Output directory")
    parser.add_argument("-n", "--ngram", default=3, help="Size of N-grams", type=int)
    parser.add_argument("-t", "--topn", default=20, help="Top max features ordered by term frequency across the corpus",
                        type=int)

    args = parser.parse_args()

    print('Arguments:\t{}\n\n'.format('\n\t\t'.join(f'{k}={v}' for k, v in vars(args).items())))

    utc_time = datetime.datetime.utcnow()
    now = utc_time.strftime('%Y%m%d%H%M%S')

    perform_fet_ext_sel(args, now)